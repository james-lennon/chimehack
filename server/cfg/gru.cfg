[net]
inputs=256

# Test
batch = 1
time_steps=1

# Train
# batch = 512
# time_steps=64

subdivisions=1
momentum=0.9
decay=0.001
learning_rate=0.1

burn_in=100
policy=poly
power=4
max_batches=10000

[gru]
batch_normalize=1
output = 1024
tanh = 1

[gru]
batch_normalize=1
output = 1024
tanh = 1

[gru]
batch_normalize=1
output = 1024
tanh = 1

[connected]
output=256
activation=linear

[softmax]

[cost]
type=sse

